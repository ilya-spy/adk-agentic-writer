"""Reviewer agent for reviewing and improving generated content.

Implements: AgentProtocol + EditorialProtocol
Uses: Editorial models for feedback and quality metrics
"""

import logging
from typing import Any, Dict

from ...models.agent_models import AgentRole, AgentStatus
from ...models.editorial_models import (
    Feedback,
    FeedbackType,
    QualityMetrics,
    ValidationResult,
)
from ..base_agent import BaseAgent

logger = logging.getLogger(__name__)


class ReviewerAgent(BaseAgent):
    """Agent specialized in reviewing and improving content quality.
    
    Implements:
    - AgentProtocol: process_task, update_status, get_state, receive_message
    - EditorialProtocol: generate_content, validate_content, refine_content
    
    Uses:
    - Editorial models for structured feedback and quality metrics
    """

    def __init__(self, agent_id: str = "static_reviewer", config: Dict[str, Any] | None = None):
        """Initialize the reviewer agent."""
        super().__init__(agent_id, AgentRole.REVIEWER, config)

    async def process_task(self, task_description: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        Review and improve content generated by other agents.

        Args:
            task_description: Description of the review task
            parameters: Parameters including the content to review

        Returns:
            Dict containing the reviewed/improved content
        """
        await self.update_status(AgentStatus.WORKING)
        
        content = parameters.get("content", {})
        content_type = parameters.get("content_type")
        
        logger.info(f"Reviewing {content_type} content")
        
        # Perform review (in production, would use LLM for sophisticated review)
        reviewed_content = await self._review_content(content, content_type)
        
        await self.update_status(AgentStatus.COMPLETED)
        
        return reviewed_content

    async def _review_content(self, content: Dict[str, Any], content_type: str) -> Dict[str, Any]:
        """Review and potentially improve the content using editorial models."""
        # Create quality metrics
        quality_metrics = QualityMetrics(
            overall_score=85.0,
            grammar_score=90.0,
            clarity_score=85.0,
            accuracy_score=88.0,
            engagement_score=80.0,
            completeness_score=85.0,
            issues_found=[
                "Minor clarity improvements possible",
                "Could add more engaging elements"
            ],
            strengths=[
                "Content structure is well-organized",
                "Clear progression through material",
                "Good educational value"
            ],
            evaluated_by=self.agent_id
        )
        
        # Create feedback
        feedback = [
            Feedback(
                feedback_id=f"fb_{self.agent_id}_1",
                feedback_type=FeedbackType.CLARITY,
                content="Overall content is clear and well-structured",
                severity="low",
                created_by=self.agent_id
            ),
            Feedback(
                feedback_id=f"fb_{self.agent_id}_2",
                feedback_type=FeedbackType.ENGAGEMENT,
                content="Consider adding more interactive elements",
                severity="medium",
                suggested_fix="Add more varied question types or interactive scenarios",
                created_by=self.agent_id
            )
        ]
        
        # Create validation result
        validation = ValidationResult(
            is_valid=True,
            validation_score=quality_metrics.overall_score,
            errors=[],
            warnings=quality_metrics.issues_found,
            suggestions=[f.content for f in feedback if f.suggested_fix],
            validated_by=self.agent_id
        )
        
        # Return review with editorial models
        return {
            "original_content": content,
            "quality_metrics": quality_metrics.model_dump(),
            "feedback": [f.model_dump() for f in feedback],
            "validation": validation.model_dump(),
            "reviewed_by": self.agent_id,
            "approved": validation.is_valid and quality_metrics.overall_score >= 70.0
        }

    async def generate_content(self, prompt: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate review content based on prompt and parameters.

        Args:
            prompt: Content generation prompt
            parameters: Generation parameters

        Returns:
            Dict containing reviewed content
        """
        return await self.process_task(prompt, parameters)

    async def validate_content(self, content: Dict[str, Any]) -> bool:
        """
        Validate content structure.

        Args:
            content: Content to validate

        Returns:
            True if content is valid, False otherwise
        """
        # Reviewer validates any content structure
        return isinstance(content, dict)

    async def refine_content(self, content: Dict[str, Any], feedback: str) -> Dict[str, Any]:
        """
        Refine content based on feedback.

        Args:
            content: Content to refine
            feedback: Feedback for refinement

        Returns:
            Dict containing refined content
        """
        # Reviewer's refine is essentially a review pass
        return await self._review_content(content, content.get("content_type", "unknown"))
